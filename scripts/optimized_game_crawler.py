#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆæ¸¸æˆçˆ¬è™« - é«˜æ•ˆç‡ã€å¤šå¹³å°ã€æ™ºèƒ½å»é‡
è§£å†³é—®é¢˜ï¼š
1. æé«˜çˆ¬å–æ•ˆç‡ï¼ˆå¹¶å‘çˆ¬å–ï¼‰
2. å¢åŠ æ›´å¤šæ¸¸æˆå¹³å°
3. æ™ºèƒ½å»é‡é¿å…é‡å¤
4. è‡ªåŠ¨ä¸‹è½½ç¼©ç•¥å›¾
5. æ›´å®½æ¾çš„æ¸¸æˆéªŒè¯
"""

import requests
from bs4 import BeautifulSoup
import asyncio
import aiohttp
import json
import random
import time
import os
import logging
import re
from urllib.parse import urljoin, urlparse
from datetime import datetime
from typing import List, Dict, Optional, Set
import argparse
from PIL import Image
import io
import hashlib
import concurrent.futures
from threading import Lock

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('optimized_crawler.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# é¡¹ç›®é…ç½®
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
GAMES_DATA_FILE = os.path.join(PROJECT_ROOT, 'src', 'data', 'games.ts')
THUMBNAILS_DIR = os.path.join(PROJECT_ROOT, 'public', 'games', 'thumbnails')

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(THUMBNAILS_DIR, exist_ok=True)

# æ‰©å±•çš„æ¸¸æˆå¹³å°åˆ—è¡¨
GAME_PLATFORMS = [
    {
        'name': 'itch.io',
        'urls': [
            'https://itch.io/games/html5',
            'https://itch.io/games/html5/newest',
            'https://itch.io/games/html5/featured',
            'https://itch.io/games/html5/free',
        ],
        'game_selector': '.game_cell',
        'title_selector': '.title',
        'link_selector': 'a',
        'priority': 1
    },
    {
        'name': 'Newgrounds',
        'urls': [
            'https://www.newgrounds.com/games/browse',
            'https://www.newgrounds.com/games/browse/newest',
            'https://www.newgrounds.com/games/browse/featured',
        ],
        'game_selector': '.item-game, .portalitem-large',
        'title_selector': '.item-title, .detail-title',
        'link_selector': 'a',
        'priority': 2
    },
    {
        'name': 'Kongregate',
        'urls': [
            'https://www.kongregate.com/games',
            'https://www.kongregate.com/games/new',
            'https://www.kongregate.com/games/featured',
        ],
        'game_selector': '.game-item, .gamethumb',
        'title_selector': '.game-title, h3',
        'link_selector': 'a',
        'priority': 3
    },
    {
        'name': 'CrazyGames',
        'urls': [
            'https://www.crazygames.com/c/html5',
            'https://www.crazygames.com/c/new',
            'https://www.crazygames.com/c/trending',
        ],
        'game_selector': '.game-item, .game-tile',
        'title_selector': '.game-title, h3',
        'link_selector': 'a',
        'priority': 4
    },
    {
        'name': 'Poki',
        'urls': [
            'https://poki.com/en/g/new',
            'https://poki.com/en/g/trending',
            'https://poki.com/en/g/top-rated',
        ],
        'game_selector': '.game-item, .game-card',
        'title_selector': '.game-title, h3',
        'link_selector': 'a',
        'priority': 5
    }
]

# æ”¾å®½çš„æ¸¸æˆåŸŸåç™½åå•
GAME_DOMAINS = [
    # åŸæœ‰çš„ç™½åå•
    'html-classic.itch.zone', 'v6p9d9t4.ssl.hwcdn.net', 'kdata.itch.zone', 'assets.itch.zone',
    'uploads.ungrounded.net', 'www.newgrounds.com', 'newgrounds.com',
    'gamejolt.net', 'cdn.gamejolt.net',
    'crazygames.com', 'embed.crazygames.com', 'poki.com', 'embed.poki.com',
    'kongregate.com', 'armor.ag', 'html5.gamedistribution.com',
    
    # æ–°å¢çš„æ¸¸æˆåŸŸåï¼ˆæ›´å®½æ¾ï¼‰
    'armorgames.com', 'addictinggames.com', 'miniclip.com', 'y8.com',
    'friv.com', 'kizi.com', 'agame.com', 'silvergames.com',
    'gameforge.com', 'mousecity.com', 'games.co.uk', 'girlsgogames.com',
    'mousebreaker.com', 'gamesfreak.net', 'primarygames.com',
    'cdn.', 'static.', 'assets.', 'media.', 'content.',  # CDNåŸŸå
    'github.io', 'githubusercontent.com', 'netlify.app', 'vercel.app',  # æ‰˜ç®¡å¹³å°
]

class OptimizedGameCrawler:
    def __init__(self, max_games: int = 50):
        self.max_games = max_games
        self.found_games = []
        self.existing_titles = set()
        self.existing_urls = set()
        self.session = requests.Session()
        self.lock = Lock()
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        # åŠ è½½ç°æœ‰æ¸¸æˆé¿å…é‡å¤
        self._load_existing_games()
    
    def _load_existing_games(self):
        """åŠ è½½ç°æœ‰æ¸¸æˆä»¥é¿å…é‡å¤"""
        try:
            with open(GAMES_DATA_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–æ ‡é¢˜å’ŒURL
            title_pattern = r'title:\s*[\'"]([^\'"]+)[\'"]'
            url_pattern = r'iframeUrl:\s*[\'"]([^\'"]+)[\'"]'
            
            titles = re.findall(title_pattern, content)
            urls = re.findall(url_pattern, content)
            
            self.existing_titles = {title.lower().strip() for title in titles}
            self.existing_urls = set(urls)
            
            logger.info(f"ğŸ“š å·²åŠ è½½ {len(self.existing_titles)} ä¸ªç°æœ‰æ¸¸æˆæ ‡é¢˜ï¼Œ{len(self.existing_urls)} ä¸ªURL")
            
        except Exception as e:
            logger.warning(f"åŠ è½½ç°æœ‰æ¸¸æˆå¤±è´¥: {e}")
    
    def is_duplicate(self, title: str, url: str = None) -> bool:
        """æ£€æŸ¥æ˜¯å¦é‡å¤"""
        title_clean = title.lower().strip()
        
        # æ£€æŸ¥æ ‡é¢˜é‡å¤
        if title_clean in self.existing_titles:
            return True
        
        # æ£€æŸ¥URLé‡å¤
        if url and url in self.existing_urls:
            return True
        
        # æ£€æŸ¥å·²æ‰¾åˆ°çš„æ¸¸æˆä¸­æ˜¯å¦é‡å¤
        for game in self.found_games:
            if game['title'].lower().strip() == title_clean:
                return True
            if url and game.get('iframeUrl') == url:
                return True
        
        return False
    
    def crawl_platform(self, platform: Dict) -> List[Dict]:
        """çˆ¬å–å•ä¸ªå¹³å°çš„æ¸¸æˆ"""
        platform_games = []
        
        try:
            logger.info(f"ğŸ® å¼€å§‹çˆ¬å–å¹³å°: {platform['name']}")
            
            for url in platform['urls']:
                if len(platform_games) >= 10:  # æ¯ä¸ªå¹³å°æœ€å¤š10ä¸ªæ¸¸æˆ
                    break
                
                try:
                    response = self.session.get(url, timeout=10)
                    if response.status_code != 200:
                        logger.warning(f"âŒ {platform['name']} - {url}: HTTP {response.status_code}")
                        continue
                    
                    soup = BeautifulSoup(response.text, 'html.parser')
                    games = self._extract_games_from_page(soup, platform, url)
                    platform_games.extend(games)
                    
                    logger.info(f"âœ… {platform['name']} - {url}: æ‰¾åˆ° {len(games)} ä¸ªæ¸¸æˆ")
                    
                    # çŸ­æš‚å»¶è¿Ÿ
                    time.sleep(random.uniform(0.5, 1.0))
                    
                except Exception as e:
                    logger.warning(f"âŒ {platform['name']} - {url}: {e}")
                    continue
        
        except Exception as e:
            logger.error(f"âŒ å¹³å° {platform['name']} çˆ¬å–å¤±è´¥: {e}")
        
        logger.info(f"ğŸ¯ {platform['name']} æ€»å…±æ‰¾åˆ° {len(platform_games)} ä¸ªæ¸¸æˆ")
        return platform_games
    
    def _extract_games_from_page(self, soup: BeautifulSoup, platform: Dict, base_url: str) -> List[Dict]:
        """ä»é¡µé¢æå–æ¸¸æˆä¿¡æ¯"""
        games = []
        
        try:
            # å°è¯•é…ç½®çš„é€‰æ‹©å™¨
            game_elements = soup.select(platform['game_selector'])
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•é€šç”¨é€‰æ‹©å™¨
            if not game_elements:
                generic_selectors = [
                    '.game', '.game-item', '.game-card', '.item', '.card',
                    '[class*="game"]', '[class*="item"]', 'article'
                ]
                for selector in generic_selectors:
                    game_elements = soup.select(selector)
                    if len(game_elements) > 3:  # è‡³å°‘è¦æœ‰å‡ ä¸ªå…ƒç´ 
                        break
            
            logger.debug(f"ğŸ” {platform['name']}: æ‰¾åˆ° {len(game_elements)} ä¸ªæ¸¸æˆå…ƒç´ ")
            
            for element in game_elements[:15]:  # é™åˆ¶æ¯é¡µæœ€å¤š15ä¸ª
                try:
                    game_info = self._extract_game_info(element, platform, base_url)
                    if game_info and not self.is_duplicate(game_info['title'], game_info.get('iframeUrl')):
                        games.append(game_info)
                        # æ·»åŠ åˆ°å·²çŸ¥æ¸¸æˆä¸­é˜²æ­¢é‡å¤
                        self.existing_titles.add(game_info['title'].lower().strip())
                        if game_info.get('iframeUrl'):
                            self.existing_urls.add(game_info['iframeUrl'])
                
                except Exception as e:
                    logger.debug(f"æå–æ¸¸æˆä¿¡æ¯å¤±è´¥: {e}")
                    continue
        
        except Exception as e:
            logger.warning(f"é¡µé¢è§£æå¤±è´¥: {e}")
        
        return games
    
    def _extract_game_info(self, element, platform: Dict, base_url: str) -> Optional[Dict]:
        """ä»å…ƒç´ æå–æ¸¸æˆä¿¡æ¯"""
        try:
            # æå–æ ‡é¢˜
            title = self._extract_title(element, platform)
            if not title or len(title.strip()) < 2:
                return None
            
            # æå–é“¾æ¥
            link_elem = element.select_one(platform.get('link_selector', 'a'))
            if not link_elem:
                if element.name == 'a':
                    link_elem = element
                else:
                    return None
            
            game_url = urljoin(base_url, link_elem.get('href', ''))
            if not game_url:
                return None
            
            # æå–æˆ–ç”Ÿæˆiframe URL
            iframe_url = self._find_or_generate_iframe_url(game_url, platform['name'])
            if not iframe_url:
                return None
            
            # æå–ç¼©ç•¥å›¾
            thumbnail_url = self._extract_thumbnail_url(element, base_url)
            
            # ç”Ÿæˆæ¸¸æˆä¿¡æ¯
            game_id = f"{platform['name'].lower()}_{int(time.time())}_{random.randint(1000, 9999)}"
            
            game_info = {
                'id': game_id,
                'title': self._clean_title(title),
                'description': f"æ¥è‡ª{platform['name']}çš„HTML5æ¸¸æˆ",
                'category': self._categorize_game(title),
                'categoryId': self._get_category_id(title),
                'thumbnail': thumbnail_url or '/games/thumbnails/default.jpg',
                'path': f'/games/{game_id}',
                'featured': False,
                'type': 'iframe',
                'iframeUrl': iframe_url,
                'addedAt': datetime.now().strftime('%Y-%m-%d'),
                'tags': ['HTML5', 'åœ¨çº¿', platform['name']]
            }
            
            return game_info
            
        except Exception as e:
            logger.debug(f"æå–æ¸¸æˆä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _extract_title(self, element, platform: Dict) -> str:
        """æå–æ¸¸æˆæ ‡é¢˜"""
        # å°è¯•é…ç½®çš„æ ‡é¢˜é€‰æ‹©å™¨
        title_selectors = [platform.get('title_selector', '')]
        
        # æ·»åŠ é€šç”¨æ ‡é¢˜é€‰æ‹©å™¨
        title_selectors.extend([
            '.title', '.name', '.game-title', '.game-name',
            'h1', 'h2', 'h3', 'h4', 'h5',
            '[class*="title"]', '[class*="name"]',
            'a[title]', 'img[alt]'
        ])
        
        for selector in title_selectors:
            if not selector:
                continue
            
            try:
                elem = element.select_one(selector)
                if elem:
                    # å°è¯•æ–‡æœ¬å†…å®¹
                    title = elem.get_text(strip=True)
                    if title and len(title) > 2:
                        return title
                    
                    # å°è¯•titleå±æ€§
                    title = elem.get('title', '').strip()
                    if title and len(title) > 2:
                        return title
                    
                    # å°è¯•altå±æ€§
                    title = elem.get('alt', '').strip()
                    if title and len(title) > 2:
                        return title
            except:
                continue
        
        # æœ€åå°è¯•ç¬¬ä¸€ä¸ªé“¾æ¥çš„æ–‡æœ¬
        link = element.select_one('a')
        if link:
            title = link.get_text(strip=True)
            if title and len(title) > 2:
                return title
        
        return ""
    
    def _extract_thumbnail_url(self, element, base_url: str) -> Optional[str]:
        """æå–ç¼©ç•¥å›¾URL"""
        img_selectors = ['img', '.thumb img', '.thumbnail img', '.game-thumb img']
        
        for selector in img_selectors:
            try:
                img = element.select_one(selector)
                if img:
                    src = img.get('src') or img.get('data-src') or img.get('data-lazy')
                    if src:
                        full_url = urljoin(base_url, src)
                        if self._is_valid_image_url(full_url):
                            return self._download_and_save_thumbnail(full_url)
            except:
                continue
        
        return None
    
    def _is_valid_image_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡URL"""
        if not url:
            return False
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        parsed = urlparse(url.lower())
        path = parsed.path
        
        image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']
        if any(path.endswith(ext) for ext in image_extensions):
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡ç›¸å…³å‚æ•°
        if any(keyword in url.lower() for keyword in ['thumb', 'preview', 'cover', 'image']):
            return True
        
        return False
    
    def _download_and_save_thumbnail(self, url: str) -> str:
        """ä¸‹è½½å¹¶ä¿å­˜ç¼©ç•¥å›¾"""
        try:
            response = self.session.get(url, timeout=5, stream=True)
            if response.status_code != 200:
                return None
            
            # æ£€æŸ¥å†…å®¹ç±»å‹
            content_type = response.headers.get('content-type', '').lower()
            if not any(img_type in content_type for img_type in ['image/jpeg', 'image/png', 'image/gif', 'image/webp']):
                return None
            
            # ç”Ÿæˆæ–‡ä»¶å
            url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
            timestamp = int(time.time())
            filename = f"game_{timestamp}_{url_hash}.jpg"
            filepath = os.path.join(THUMBNAILS_DIR, filename)
            
            # ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
            img_data = response.content
            
            # å°è¯•ç”¨PILå¤„ç†å›¾ç‰‡ï¼ˆè½¬æ¢æ ¼å¼ã€è°ƒæ•´å¤§å°ï¼‰
            try:
                img = Image.open(io.BytesIO(img_data))
                
                # è½¬æ¢ä¸ºRGBï¼ˆå»é™¤é€æ˜é€šé“ï¼‰
                if img.mode in ('RGBA', 'LA', 'P'):
                    img = img.convert('RGB')
                
                # è°ƒæ•´å¤§å°ï¼ˆæœ€å¤§300x200ï¼‰
                img.thumbnail((300, 200), Image.Resampling.LANCZOS)
                
                # ä¿å­˜
                img.save(filepath, 'JPEG', quality=85, optimize=True)
                
                logger.debug(f"âœ… ä¸‹è½½ç¼©ç•¥å›¾: {filename}")
                return f'/games/thumbnails/{filename}'
                
            except Exception as e:
                # å¦‚æœPILå¤„ç†å¤±è´¥ï¼Œç›´æ¥ä¿å­˜åŸæ–‡ä»¶
                with open(filepath, 'wb') as f:
                    f.write(img_data)
                
                logger.debug(f"âœ… ä¸‹è½½ç¼©ç•¥å›¾ï¼ˆåŸæ ¼å¼ï¼‰: {filename}")
                return f'/games/thumbnails/{filename}'
        
        except Exception as e:
            logger.debug(f"ä¸‹è½½ç¼©ç•¥å›¾å¤±è´¥ {url}: {e}")
            return None
    
    def _find_or_generate_iframe_url(self, game_url: str, platform_name: str) -> Optional[str]:
        """æŸ¥æ‰¾æˆ–ç”Ÿæˆiframe URL"""
        try:
            # å¯¹äºæŸäº›å¹³å°ï¼Œå¯ä»¥ç›´æ¥æ¨æ–­iframe URL
            if platform_name.lower() == 'itch.io':
                return self._generate_itch_iframe_url(game_url)
            elif platform_name.lower() == 'newgrounds':
                return self._generate_newgrounds_iframe_url(game_url)
            elif platform_name.lower() == 'kongregate':
                return self._generate_kongregate_iframe_url(game_url)
            elif platform_name.lower() == 'crazygames':
                return self._generate_crazygames_iframe_url(game_url)
            
            # å°è¯•è®¿é—®æ¸¸æˆé¡µé¢æŸ¥æ‰¾iframe
            response = self.session.get(game_url, timeout=5)
            if response.status_code != 200:
                return None
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾iframe
            iframes = soup.select('iframe[src]')
            for iframe in iframes:
                src = iframe.get('src')
                if src and self._is_valid_game_iframe(src):
                    return urljoin(game_url, src)
            
            # æŸ¥æ‰¾å…¶ä»–åµŒå…¥æ–¹å¼
            embeds = soup.select('[data-src], [data-game-url], [data-embed-url]')
            for embed in embeds:
                for attr in ['data-src', 'data-game-url', 'data-embed-url']:
                    url = embed.get(attr)
                    if url and self._is_valid_game_iframe(url):
                        return urljoin(game_url, url)
            
            return None
            
        except Exception as e:
            logger.debug(f"æŸ¥æ‰¾iframeå¤±è´¥ {game_url}: {e}")
            return None
    
    def _generate_itch_iframe_url(self, game_url: str) -> Optional[str]:
        """ä¸ºitch.ioç”Ÿæˆiframe URL"""
        try:
            # itch.ioçš„æ¸¸æˆé€šå¸¸æœ‰æ ‡å‡†çš„iframeæ ¼å¼
            parsed = urlparse(game_url)
            if 'itch.io' in parsed.netloc:
                # å°è¯•å‡ ç§å¸¸è§çš„iframeæ¨¡å¼
                patterns = [
                    f"https://html-classic.itch.zone/html/{parsed.path.split('/')[-1]}/index.html",
                    f"{game_url}/embed",
                    f"{game_url.rstrip('/')}/embed"
                ]
                
                for pattern in patterns:
                    if self._test_iframe_url(pattern):
                        return pattern
            
            return game_url  # ä½œä¸ºå¤‡é€‰
        except:
            return None
    
    def _generate_newgrounds_iframe_url(self, game_url: str) -> Optional[str]:
        """ä¸ºNewgroundsç”Ÿæˆiframe URL"""
        # Newgroundsçš„æ¸¸æˆé¡µé¢é€šå¸¸å°±æ˜¯å¯åµŒå…¥çš„
        return game_url
    
    def _generate_kongregate_iframe_url(self, game_url: str) -> Optional[str]:
        """ä¸ºKongregateç”Ÿæˆiframe URL"""
        try:
            parsed = urlparse(game_url)
            if '/games/' in parsed.path:
                # Kongregateçš„iframeæ¨¡å¼
                game_id = parsed.path.split('/')[-1]
                return f"https://www.kongregate.com/games/{game_id}/embed"
        except:
            pass
        return game_url
    
    def _generate_crazygames_iframe_url(self, game_url: str) -> Optional[str]:
        """ä¸ºCrazyGamesç”Ÿæˆiframe URL"""
        try:
            parsed = urlparse(game_url)
            if '/game/' in parsed.path:
                return f"https://embed.crazygames.com{parsed.path}"
        except:
            pass
        return game_url
    
    def _test_iframe_url(self, url: str) -> bool:
        """æµ‹è¯•iframe URLæ˜¯å¦æœ‰æ•ˆ"""
        try:
            response = self.session.head(url, timeout=3)
            return response.status_code == 200
        except:
            return False
    
    def _is_valid_game_iframe(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ¸¸æˆiframe URLï¼ˆæ›´å®½æ¾çš„éªŒè¯ï¼‰"""
        if not url:
            return False
        
        url_lower = url.lower()
        parsed = urlparse(url)
        
        # ç™½åå•åŸŸåæ£€æŸ¥ï¼ˆæ›´å®½æ¾ï¼‰
        for domain in GAME_DOMAINS:
            if domain in parsed.netloc or domain in url_lower:
                return True
        
        # æ¸¸æˆç›¸å…³è·¯å¾„æ£€æŸ¥
        game_patterns = [
            '/game/', '/games/', '/play/', '/embed/', '/player/',
            '/html5/', '/swf/', '/unity/', '/webgl/', '/canvas/',
            'game.html', 'index.html', 'play.html'
        ]
        
        for pattern in game_patterns:
            if pattern in url_lower:
                return True
        
        # é¿å…æ˜æ˜¾çš„éæ¸¸æˆå†…å®¹
        exclude_patterns = [
            'ads', 'analytics', 'tracking', 'social', 'comment',
            'youtube', 'facebook', 'twitter', 'discord'
        ]
        
        for pattern in exclude_patterns:
            if pattern in url_lower:
                return False
        
        # é»˜è®¤æ¥å—ï¼ˆæ›´å®½æ¾çš„ç­–ç•¥ï¼‰
        return True
    
    def _clean_title(self, title: str) -> str:
        """æ¸…ç†æ¸¸æˆæ ‡é¢˜"""
        # ç§»é™¤å¸¸è§çš„åç¼€å’Œå‰ç¼€
        patterns_to_remove = [
            r'\s*-\s*Play Online.*$',
            r'\s*\|\s*Free Game.*$',
            r'\s*-\s*Browser Game.*$',
            r'\s*Online.*$',
            r'^\s*Play\s+',
            r'\s*Game\s*$'
        ]
        
        for pattern in patterns_to_remove:
            title = re.sub(pattern, '', title, flags=re.IGNORECASE)
        
        return title.strip()
    
    def _categorize_game(self, title: str) -> str:
        """è‡ªåŠ¨åˆ†ç±»æ¸¸æˆ"""
        title_lower = title.lower()
        
        if any(word in title_lower for word in ['puzzle', 'match', 'brain', 'logic', 'sudoku', 'tetris']):
            return 'ç›Šæ™º'
        elif any(word in title_lower for word in ['action', 'shoot', 'fight', 'run', 'jump', 'platform']):
            return 'åŠ¨ä½œ'
        elif any(word in title_lower for word in ['card', 'poker', 'solitaire', 'blackjack']):
            return 'å¡ç‰Œ'
        elif any(word in title_lower for word in ['sport', 'football', 'soccer', 'basketball', 'tennis']):
            return 'ä½“è‚²'
        elif any(word in title_lower for word in ['chess', 'checkers', 'board', 'strategy']):
            return 'æ£‹ç›˜'
        else:
            return 'ä¼‘é—²'
    
    def _get_category_id(self, title: str) -> str:
        """è·å–åˆ†ç±»ID"""
        category = self._categorize_game(title)
        category_map = {
            'ä¼‘é—²': '1',
            'ç›Šæ™º': '2',
            'åŠ¨ä½œ': '3',
            'å¡ç‰Œ': '4',
            'ä½“è‚²': '5',
            'æ£‹ç›˜': '6'
        }
        return category_map.get(category, '1')
    
    def crawl_all_platforms(self) -> List[Dict]:
        """å¹¶å‘çˆ¬å–æ‰€æœ‰å¹³å°"""
        logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘çˆ¬å– {len(GAME_PLATFORMS)} ä¸ªå¹³å°ï¼Œç›®æ ‡ {self.max_games} ä¸ªæ¸¸æˆ")
        
        all_games = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘çˆ¬å–
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            future_to_platform = {
                executor.submit(self.crawl_platform, platform): platform 
                for platform in GAME_PLATFORMS
            }
            
            for future in concurrent.futures.as_completed(future_to_platform):
                platform = future_to_platform[future]
                try:
                    games = future.result(timeout=60)  # æ¯ä¸ªå¹³å°æœ€å¤š60ç§’
                    all_games.extend(games)
                    
                    logger.info(f"âœ… {platform['name']} å®Œæˆï¼Œæ‰¾åˆ° {len(games)} ä¸ªæ¸¸æˆ")
                    
                    # å¦‚æœå·²ç»æ‰¾åˆ°è¶³å¤Ÿçš„æ¸¸æˆï¼Œå¯ä»¥æå‰åœæ­¢
                    if len(all_games) >= self.max_games:
                        logger.info(f"ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {self.max_games}ï¼Œåœæ­¢çˆ¬å–")
                        break
                        
                except Exception as e:
                    logger.error(f"âŒ {platform['name']} çˆ¬å–å¤±è´¥: {e}")
        
        # å»é‡å’Œæ’åº
        unique_games = self._deduplicate_games(all_games)
        
        # é™åˆ¶æ•°é‡
        final_games = unique_games[:self.max_games]
        
        logger.info(f"ğŸ‰ çˆ¬å–å®Œæˆï¼æ€»å…±æ‰¾åˆ° {len(final_games)} ä¸ªå”¯ä¸€æ¸¸æˆ")
        return final_games
    
    def _deduplicate_games(self, games: List[Dict]) -> List[Dict]:
        """å»é‡æ¸¸æˆ"""
        seen_titles = set()
        seen_urls = set()
        unique_games = []
        
        for game in games:
            title_key = game['title'].lower().strip()
            url_key = game.get('iframeUrl', '')
            
            if title_key not in seen_titles and url_key not in seen_urls:
                seen_titles.add(title_key)
                if url_key:
                    seen_urls.add(url_key)
                unique_games.append(game)
        
        logger.info(f"ğŸ”„ å»é‡å®Œæˆ: {len(unique_games)}/{len(games)} ä¸ªå”¯ä¸€æ¸¸æˆ")
        return unique_games
    
    def save_games(self, games: List[Dict]):
        """ä¿å­˜æ¸¸æˆåˆ°æ–‡ä»¶"""
        try:
            # è¯»å–ç°æœ‰æ•°æ®
            existing_games = []
            try:
                with open(GAMES_DATA_FILE, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æç°æœ‰æ¸¸æˆ
                existing_games = self._parse_existing_games(content)
                
            except Exception as e:
                logger.warning(f"è¯»å–ç°æœ‰æ¸¸æˆå¤±è´¥: {e}")
            
            # åˆå¹¶æ¸¸æˆ
            all_games = existing_games + games
            
            # å»é‡
            all_games = self._deduplicate_games(all_games)
            
            # ç”Ÿæˆæ–°æ–‡ä»¶å†…å®¹
            new_content = self._generate_games_file_content(all_games)
            
            # å¤‡ä»½åŸæ–‡ä»¶
            backup_file = f"{GAMES_DATA_FILE}.backup.{int(time.time())}"
            if os.path.exists(GAMES_DATA_FILE):
                import shutil
                shutil.copy2(GAMES_DATA_FILE, backup_file)
                logger.info(f"ğŸ“ å·²å¤‡ä»½åŸæ–‡ä»¶: {backup_file}")
            
            # å†™å…¥æ–°æ–‡ä»¶
            with open(GAMES_DATA_FILE, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(all_games)} ä¸ªæ¸¸æˆåˆ° {GAMES_DATA_FILE}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ¸¸æˆå¤±è´¥: {e}")
    
    def _parse_existing_games(self, content: str) -> List[Dict]:
        """è§£æç°æœ‰æ¸¸æˆæ•°æ®"""
        games = []
        
        try:
            # æå–gamesæ•°ç»„
            start_marker = 'export const games: Game[] = ['
            end_marker = '];'
            
            start_idx = content.find(start_marker)
            if start_idx == -1:
                return games
            
            start_idx += len(start_marker)
            end_idx = content.find(end_marker, start_idx)
            if end_idx == -1:
                return games
            
            games_str = content[start_idx:end_idx].strip()
            
            # ç®€å•çš„æ¸¸æˆå¯¹è±¡è§£æ
            game_objects = self._extract_game_objects(games_str)
            
            for game_obj in game_objects:
                game_data = self._parse_game_object(game_obj)
                if game_data:
                    games.append(game_data)
            
            logger.info(f"ğŸ“š è§£æåˆ° {len(games)} ä¸ªç°æœ‰æ¸¸æˆ")
            
        except Exception as e:
            logger.warning(f"è§£æç°æœ‰æ¸¸æˆå¤±è´¥: {e}")
        
        return games
    
    def _extract_game_objects(self, games_str: str) -> List[str]:
        """æå–æ¸¸æˆå¯¹è±¡å­—ç¬¦ä¸²"""
        objects = []
        depth = 0
        current_obj = ""
        
        for char in games_str:
            if char == '{':
                if depth == 0:
                    current_obj = "{"
                else:
                    current_obj += char
                depth += 1
            elif char == '}':
                depth -= 1
                current_obj += char
                if depth == 0:
                    objects.append(current_obj.strip())
                    current_obj = ""
            elif depth > 0:
                current_obj += char
        
        return objects
    
    def _parse_game_object(self, obj_str: str) -> Optional[Dict]:
        """è§£æå•ä¸ªæ¸¸æˆå¯¹è±¡"""
        try:
            game = {}
            
            # æå–å„ä¸ªå­—æ®µ
            patterns = {
                'id': r"id:\s*['\"]([^'\"]+)['\"]",
                'title': r"title:\s*['\"]([^'\"]+)['\"]",
                'description': r"description:\s*['\"]([^'\"]*)['\"]",
                'category': r"category:\s*['\"]([^'\"]+)['\"]",
                'categoryId': r"categoryId:\s*['\"]([^'\"]+)['\"]",
                'thumbnail': r"thumbnail:\s*['\"]([^'\"]+)['\"]",
                'path': r"path:\s*['\"]([^'\"]+)['\"]",
                'featured': r"featured:\s*(true|false)",
                'type': r"type:\s*['\"]([^'\"]+)['\"]",
                'iframeUrl': r"iframeUrl:\s*['\"]([^'\"]+)['\"]",
                'addedAt': r"addedAt:\s*['\"]([^'\"]+)['\"]"
            }
            
            for field, pattern in patterns.items():
                match = re.search(pattern, obj_str)
                if match:
                    value = match.group(1)
                    if field == 'featured':
                        game[field] = value == 'true'
                    else:
                        game[field] = value
            
            return game if 'id' in game and 'title' in game else None
            
        except Exception as e:
            logger.debug(f"è§£ææ¸¸æˆå¯¹è±¡å¤±è´¥: {e}")
            return None
    
    def _generate_games_file_content(self, games: List[Dict]) -> str:
        """ç”Ÿæˆgames.tsæ–‡ä»¶å†…å®¹"""
        # è®¡ç®—åˆ†ç±»ç»Ÿè®¡
        category_counts = {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0}
        for game in games:
            cat_id = game.get('categoryId', '1')
            if cat_id in category_counts:
                category_counts[cat_id] += 1
        
        # ç”Ÿæˆæ–‡ä»¶å†…å®¹
        content = """import { Game, Category } from '../types';

export const categories: Category[] = [
  { id: '1', name: 'ä¼‘é—²', description: 'ç®€å•æœ‰è¶£çš„ä¼‘é—²æ¸¸æˆï¼Œé€‚åˆæ‰€æœ‰å¹´é¾„æ®µç©å®¶', count: """ + str(category_counts['1']) + """, slug: 'casual' },
  { id: '2', name: 'ç›Šæ™º', description: 'é”»ç‚¼å¤§è„‘çš„ç›Šæ™ºæ¸¸æˆï¼Œæå‡æ€ç»´èƒ½åŠ›', count: """ + str(category_counts['2']) + """, slug: 'puzzle' },
  { id: '3', name: 'åŠ¨ä½œ', description: 'åˆºæ¿€çš„åŠ¨ä½œæ¸¸æˆï¼Œè€ƒéªŒä½ çš„ååº”é€Ÿåº¦', count: """ + str(category_counts['3']) + """, slug: 'action' },
  { id: '4', name: 'å¡ç‰Œ', description: 'å¡ç‰Œå’Œæ£‹ç‰Œç±»æ¸¸æˆï¼Œç­–ç•¥ä¸è¿æ°”çš„ç»“åˆ', count: """ + str(category_counts['4']) + """, slug: 'card' },
  { id: '5', name: 'ä½“è‚²', description: 'å„ç±»ä½“è‚²æ¨¡æ‹Ÿæ¸¸æˆï¼Œæ„Ÿå—ä½“è‚²ç«æŠ€çš„ä¹è¶£', count: """ + str(category_counts['5']) + """, slug: 'sports' },
  { id: '6', name: 'æ£‹ç›˜', description: 'ç»å…¸çš„æ£‹ç›˜æ¸¸æˆï¼Œè€ƒéªŒæˆ˜ç•¥æ€ç»´', count: """ + str(category_counts['6']) + """, slug: 'board' },
];

export const games: Game[] = [
"""
        
        # ç”Ÿæˆæ¸¸æˆæ•°ç»„
        for game in games:
            content += "  {\n"
            content += f"    id: '{game['id']}',\n"
            content += f"    title: '{game['title']}',\n"
            content += f"    description: '{game.get('description', '')}',\n"
            content += f"    category: '{game.get('category', 'ä¼‘é—²')}',\n"
            content += f"    categoryId: '{game.get('categoryId', '1')}',\n"
            content += f"    thumbnail: '{game.get('thumbnail', '/games/thumbnails/default.jpg')}',\n"
            content += f"    path: '{game.get('path', f'/games/{game['id']}')}',\n"
            content += f"    featured: {str(game.get('featured', False)).lower()},\n"
            content += f"    type: '{game.get('type', 'iframe')}',\n"
            content += f"    iframeUrl: '{game.get('iframeUrl', '')}',\n"
            content += f"    addedAt: '{game.get('addedAt', datetime.now().strftime('%Y-%m-%d'))}',\n"
            
            tags = game.get('tags', ['ä¼‘é—²'])
            tags_str = ', '.join([f'"{tag}"' for tag in tags])
            content += f"    tags: [{tags_str}]\n"
            content += "  },\n"
        
        content += """];

export const getFeaturedGames = (): Game[] => {
  return games.filter(game => game.featured);
};

export const getRecentGames = (limit: number = 8): Game[] => {
  return games
    .sort((a, b) => new Date(b.addedAt).getTime() - new Date(a.addedAt).getTime())
    .slice(0, limit);
};

export const getGamesByCategory = (categoryId: string): Game[] => {
  return games.filter(game => game.categoryId === categoryId);
};

export const getGameById = (id: string): Game | undefined => {
  return games.find(game => game.id === id);
};

export const getCategoryById = (id: string): Category | undefined => {
  return categories.find(category => category.id === id);
};
"""
        
        return content

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–ç‰ˆæ¸¸æˆçˆ¬è™« - é«˜æ•ˆç‡ã€å¤šå¹³å°ã€æ™ºèƒ½å»é‡')
    parser.add_argument('--max-games', type=int, default=50, help='æœ€å¤§çˆ¬å–æ¸¸æˆæ•°é‡')
    parser.add_argument('--platforms', nargs='+', 
                       choices=['itch.io', 'newgrounds', 'kongregate', 'crazygames', 'poki'],
                       help='æŒ‡å®šè¦çˆ¬å–çš„å¹³å°')
    
    args = parser.parse_args()
    
    # è¿‡æ»¤å¹³å°
    if args.platforms:
        global GAME_PLATFORMS
        GAME_PLATFORMS = [p for p in GAME_PLATFORMS if p['name'].lower() in [name.lower() for name in args.platforms]]
        logger.info(f"ğŸ¯ ä»…çˆ¬å–æŒ‡å®šå¹³å°: {[p['name'] for p in GAME_PLATFORMS]}")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = OptimizedGameCrawler(max_games=args.max_games)
    
    # å¼€å§‹çˆ¬å–
    games = crawler.crawl_all_platforms()
    
    if games:
        # ä¿å­˜æ¸¸æˆ
        crawler.save_games(games)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info("ğŸ“Š çˆ¬å–ç»Ÿè®¡:")
        logger.info(f"  ğŸ“ˆ æ€»æ¸¸æˆæ•°: {len(games)}")
        
        platform_stats = {}
        for game in games:
            platform = game['tags'][-1] if game['tags'] else 'Unknown'
            platform_stats[platform] = platform_stats.get(platform, 0) + 1
        
        for platform, count in platform_stats.items():
            logger.info(f"  ğŸ® {platform}: {count} ä¸ªæ¸¸æˆ")
        
        # ç»Ÿè®¡ç¼©ç•¥å›¾
        thumbnails_with_custom = sum(1 for game in games if not game['thumbnail'].endswith('default.jpg'))
        logger.info(f"  ğŸ–¼ï¸ è‡ªå®šä¹‰ç¼©ç•¥å›¾: {thumbnails_with_custom}/{len(games)} ä¸ª")
        
        logger.info("ğŸ‰ ä¼˜åŒ–ç‰ˆçˆ¬è™«æ‰§è¡Œå®Œæˆï¼")
    else:
        logger.warning("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¸¸æˆ")

if __name__ == '__main__':
    main()
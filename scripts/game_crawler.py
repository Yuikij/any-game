#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¸æˆçˆ¬è™«è„šæœ¬ - å…¨ç½‘æœç´¢æ¸¸æˆèµ„æºå¹¶æ‰©å……é¡¹ç›®æ¸¸æˆåº“
æ”¯æŒæœç´¢iframeåµŒå…¥å¼æ¸¸æˆå’ŒHTMLé™æ€æ¸¸æˆä¸¤ç§ç±»å‹
"""

import requests
from bs4 import BeautifulSoup
import json
import random
import time
import os
import re
import hashlib
from urllib.parse import urljoin, urlparse, quote
from http.client import RemoteDisconnected
from requests.exceptions import RequestException, Timeout
from tenacity import retry, stop_after_attempt, wait_fixed
import logging
from datetime import datetime
from typing import List, Dict, Optional, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('game_crawler.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# é¡¹ç›®é…ç½®
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
GAMES_DATA_FILE = os.path.join(PROJECT_ROOT, 'src', 'data', 'games.ts')
THUMBNAILS_DIR = os.path.join(PROJECT_ROOT, 'public', 'games', 'thumbnails')
STATIC_GAMES_DIR = os.path.join(PROJECT_ROOT, 'public', 'games')

# æœç´¢é…ç½® - ä¸“æ³¨äºHTML5å’Œå¯åµŒå…¥æ¸¸æˆ
SEARCH_QUERIES = [
    'site:itch.io HTML5 games embed',
    'site:gamejolt.com HTML5 browser games',
    'site:newgrounds.com HTML5 games',
    'site:kongregate.com HTML5 games',
    'site:armorgames.com HTML5 games',
    'site:crazygames.com HTML5 games',
    'site:poki.com HTML5 games',
    'HTML5 games iframe embed',
    'browser games no download',
    'online games HTML5 canvas',
    'HTML5æ¸¸æˆ åœ¨çº¿ç©',
    'ç½‘é¡µæ¸¸æˆ HTML5',
    'å…è´¹HTML5æ¸¸æˆ'
]

# å·²çŸ¥æ¸¸æˆå¹³å°ç§å­URL - ä¸“æ³¨äºå¯åµŒå…¥æ¸¸æˆçš„å¹³å°
SEED_URLS = [
    'https://itch.io/games/html5',              # itch.io HTML5æ¸¸æˆ
    'https://html-classic.itch.zone/',         # itch.ioåµŒå…¥å¼æ¸¸æˆ
    'https://gamejolt.com/games/best/html',    # GameJolt HTML5æ¸¸æˆ
    'https://www.newgrounds.com/games/browse/tag/html5', # Newgrounds HTML5
    'https://www.kongregate.com/games/new?tag=HTML5',    # Kongregate HTML5
    'https://armorgames.com/search?type=games&q=html5',  # ArmorGames HTML5
    'https://poki.com/en/g/html5',             # Poki HTML5æ¸¸æˆ
    'https://www.crazygames.com/c/html5',      # CrazyGames HTML5
    'https://html5games.com/',                 # ä¸“é—¨çš„HTML5æ¸¸æˆç½‘ç«™
    'https://www.gameflare.com/online-games/', # GameFlareåœ¨çº¿æ¸¸æˆ
    'https://www.silvergames.com/html5',       # SilverGames HTML5
    'https://www.agame.com/games/html5'        # Agame HTML5æ¸¸æˆ
]

# æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚å¤´
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}

# æ¸¸æˆåˆ†ç±»æ˜ å°„
CATEGORY_MAPPING = {
    'puzzle': 'ç›Šæ™º',
    'action': 'åŠ¨ä½œ', 
    'adventure': 'å†’é™©',
    'arcade': 'ä¼‘é—²',
    'casual': 'ä¼‘é—²',
    'strategy': 'ç­–ç•¥',
    'sports': 'ä½“è‚²',
    'racing': 'ç«é€Ÿ',
    'shooter': 'å°„å‡»',
    'platformer': 'å¹³å°',
    'rpg': 'è§’è‰²æ‰®æ¼”',
    'simulation': 'æ¨¡æ‹Ÿ',
    'card': 'å¡ç‰Œ',
    'board': 'æ£‹ç›˜',
    'music': 'éŸ³ä¹',
    'educational': 'æ•™è‚²',
    'multiplayer': 'å¤šäºº',
    'idle': 'æ”¾ç½®',
    'clicker': 'ç‚¹å‡»',
    'tower-defense': 'å¡”é˜²'
}

# é»˜è®¤åˆ†ç±»IDæ˜ å°„
CATEGORY_ID_MAPPING = {
    'ä¼‘é—²': '1',
    'ç›Šæ™º': '2', 
    'åŠ¨ä½œ': '3',
    'å¡ç‰Œ': '4',
    'ä½“è‚²': '5',
    'æ£‹ç›˜': '6'
}

class GameCrawler:
    """æ¸¸æˆçˆ¬è™«ç±»"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update(HEADERS)
        self.found_games = []
        self.processed_urls = set()
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(THUMBNAILS_DIR, exist_ok=True)
        os.makedirs(STATIC_GAMES_DIR, exist_ok=True)
    
    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
    def fetch_page(self, url: str, timeout: int = 10) -> Optional[BeautifulSoup]:
        """è·å–ç½‘é¡µå†…å®¹å¹¶è§£æ"""
        try:
            logger.info(f"æ­£åœ¨è·å–é¡µé¢: {url}")
            response = self.session.get(url, timeout=timeout)
            response.raise_for_status()
            
            # æ£€æµ‹ç¼–ç 
            if response.encoding == 'ISO-8859-1':
                response.encoding = response.apparent_encoding
            
            soup = BeautifulSoup(response.text, 'html.parser')
            return soup
            
        except (RequestException, Timeout) as e:
            logger.error(f"è·å–é¡µé¢å¤±è´¥ {url}: {e}")
            raise
        except Exception as e:
            logger.error(f"è§£æé¡µé¢å¤±è´¥ {url}: {e}")
            return None
    
    def extract_game_info(self, soup: BeautifulSoup, base_url: str) -> List[Dict]:
        """ä»é¡µé¢ä¸­æå–æ¸¸æˆä¿¡æ¯"""
        games = []
        
        # ä¸åŒç½‘ç«™çš„æ¸¸æˆé€‰æ‹©å™¨
        game_selectors = [
            # itch.io
            '.game_cell, .game_grid_widget',
            # GameJolt
            '.game-thumbnail, .game-listing-item',
            # Newgrounds
            '.item-portalitem, .portal-item',
            # Kongregate
            '.game-item, .game-thumb',
            # ArmorGames
            '.game-item, .thumb',
            # é€šç”¨é€‰æ‹©å™¨
            '[class*="game"], [class*="item"], article, .card'
        ]
        
        for selector in game_selectors:
            game_elements = soup.select(selector)
            if game_elements:
                logger.info(f"ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(game_elements)} ä¸ªæ¸¸æˆå…ƒç´ ")
                break
        
        for element in game_elements[:20]:  # é™åˆ¶æ¯é¡µæœ€å¤šå¤„ç†20ä¸ªæ¸¸æˆ
            try:
                game_info = self._extract_single_game(element, base_url)
                if game_info:
                    games.append(game_info)
            except Exception as e:
                logger.error(f"æå–æ¸¸æˆä¿¡æ¯å¤±è´¥: {e}")
                continue
        
        return games
    
    def _extract_single_game(self, element: BeautifulSoup, base_url: str) -> Optional[Dict]:
        """æå–å•ä¸ªæ¸¸æˆçš„ä¿¡æ¯"""
        try:
            # æå–æ ‡é¢˜
            title_selectors = ['h3', 'h4', '.title', '.name', '.game-title', 'a[title]', 'img[alt]']
            title = None
            for selector in title_selectors:
                title_elem = element.select_one(selector)
                if title_elem:
                    title = title_elem.get('title') or title_elem.get('alt') or title_elem.get_text(strip=True)
                    if title and len(title) > 2:
                        break
            
            if not title:
                return None
            
            # æå–é“¾æ¥
            link_elem = element.select_one('a[href]')
            if not link_elem:
                return None
            
            game_url = urljoin(base_url, link_elem['href'])
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
            if game_url in self.processed_urls:
                return None
            self.processed_urls.add(game_url)
            
            # åˆ¤æ–­æ¸¸æˆç±»å‹ - è¿™é‡Œæ˜¯å…³é”®è¿‡æ»¤æ­¥éª¤
            game_type, game_data = self._determine_game_type(game_url)
            
            # å¦‚æœæ— æ³•ç¡®å®šæ¸¸æˆç±»å‹æˆ–ä¸é€‚åˆåµŒå…¥ï¼Œè·³è¿‡è¿™ä¸ªæ¸¸æˆ
            if not game_type or not game_data:
                logger.info(f"è·³è¿‡ä¸é€‚åˆåµŒå…¥çš„æ¸¸æˆ: {title}")
                return None
            
            # æå–ç¼©ç•¥å›¾
            thumbnail_selectors = ['img[src]', '.thumbnail img', '.icon img']
            thumbnail_url = None
            for selector in thumbnail_selectors:
                img_elem = element.select_one(selector)
                if img_elem and img_elem.get('src'):
                    thumbnail_url = urljoin(base_url, img_elem['src'])
                    break
            
            # æå–æè¿°
            desc_selectors = ['.description', '.summary', '.excerpt', 'p']
            description = None
            for selector in desc_selectors:
                desc_elem = element.select_one(selector)
                if desc_elem:
                    description = desc_elem.get_text(strip=True)
                    if description and len(description) > 10:
                        break
            
            # æå–åˆ†ç±»
            category = self._extract_category(element, base_url)
            
            game_info = {
                'title': self._clean_title(title),
                'description': description or f"ä¸€æ¬¾æœ‰è¶£çš„{category}æ¸¸æˆ",
                'category': category,
                'thumbnail_url': thumbnail_url,
                'game_url': game_url,
                'type': game_type,
                'game_data': game_data
            }
            
            # éªŒè¯æ¸¸æˆæ•°æ®
            if not self.validate_game_data(game_info):
                logger.info(f"âŒ æ¸¸æˆæ•°æ®éªŒè¯å¤±è´¥ï¼Œè·³è¿‡: {title}")
                return None
            
            logger.info(f"âœ… æå–åˆ°å¯åµŒå…¥æ¸¸æˆ: {game_info['title']} ({game_type})")
            return game_info
            
        except Exception as e:
            logger.error(f"æå–å•ä¸ªæ¸¸æˆä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _extract_category(self, element: BeautifulSoup, base_url: str) -> str:
        """æå–æ¸¸æˆåˆ†ç±»"""
        # ä»å…ƒç´ ä¸­æŸ¥æ‰¾åˆ†ç±»ä¿¡æ¯
        category_selectors = ['.category', '.genre', '.tag', '[class*="category"]', '[class*="genre"]']
        
        for selector in category_selectors:
            cat_elem = element.select_one(selector)
            if cat_elem:
                cat_text = cat_elem.get_text(strip=True).lower()
                for eng_cat, cn_cat in CATEGORY_MAPPING.items():
                    if eng_cat in cat_text:
                        return cn_cat
        
        # ä»URLä¸­æ¨æ–­åˆ†ç±»
        url_lower = base_url.lower()
        for eng_cat, cn_cat in CATEGORY_MAPPING.items():
            if eng_cat in url_lower:
                return cn_cat
        
        return 'ä¼‘é—²'  # é»˜è®¤åˆ†ç±»
    
    def _determine_game_type(self, game_url: str) -> Tuple[str, Dict]:
        """åˆ¤æ–­æ¸¸æˆç±»å‹ï¼ˆiframeæˆ–staticï¼‰ï¼Œåªæ”¶é›†å¯ç›´æ¥åµŒå…¥çš„æ¸¸æˆ"""
        try:
            # è·å–æ¸¸æˆé¡µé¢
            soup = self.fetch_page(game_url)
            if not soup:
                return None, {}
            
            # 1. ä¼˜å…ˆæŸ¥æ‰¾å¯åµŒå…¥çš„iframe
            iframe_selectors = [
                'iframe[src*="html"]',  # HTML5æ¸¸æˆiframe
                'iframe[src*="game"]',  # åŒ…å«gameçš„iframe
                'iframe[src*="play"]',  # åŒ…å«playçš„iframe
                'iframe[src*="embed"]', # åµŒå…¥å¼iframe
                'iframe[src*=".io"]',   # .ioåŸŸåçš„æ¸¸æˆ
                'iframe[src*="itch.zone"]', # itch.ioçš„æ¸¸æˆiframe
                'iframe[src*="gamejolt"]',  # GameJoltçš„iframe
                'iframe[src*="newgrounds"]' # Newgroundsçš„iframe
            ]
            
            for selector in iframe_selectors:
                iframe = soup.select_one(selector)
                if iframe and iframe.get('src'):
                    iframe_src = urljoin(game_url, iframe['src'])
                    # éªŒè¯iframe URLæ˜¯å¦å¯è®¿é—®
                    if self._validate_iframe_url(iframe_src):
                        logger.info(f"æ‰¾åˆ°å¯åµŒå…¥iframe: {iframe_src}")
                        return 'iframe', {'iframe_url': iframe_src}
            
            # 2. æŸ¥æ‰¾HTML5æ¸¸æˆæ–‡ä»¶
            game_file_selectors = [
                'a[href$=".html"]',     # HTMLæ–‡ä»¶
                'a[href*="/play"]',     # åŒ…å«playçš„é“¾æ¥
                'a[href*="fullscreen"]', # å…¨å±æ¸¸æˆé“¾æ¥
                'a[href*="game.html"]', # æ¸¸æˆHTMLæ–‡ä»¶
                'a[href*="index.html"]' # ä¸»é¡µé¢æ–‡ä»¶
            ]
            
            for selector in game_file_selectors:
                for link in soup.select(selector):
                    href = link.get('href', '')
                    if href:
                        full_url = urljoin(game_url, href)
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å¯ä¸‹è½½çš„HTML5æ¸¸æˆ
                        if self._is_downloadable_game(full_url):
                            logger.info(f"æ‰¾åˆ°å¯ä¸‹è½½æ¸¸æˆ: {full_url}")
                            return 'static', {'static_url': full_url}
            
            # 3. æ£€æŸ¥æ˜¯å¦æœ‰åµŒå…¥å¼æ¸¸æˆå®¹å™¨
            game_containers = soup.select('.game-container, .game-frame, .unity-container, #game-container')
            if game_containers:
                # æŸ¥æ‰¾å®¹å™¨å†…çš„è„šæœ¬æˆ–é…ç½®
                for container in game_containers:
                    # æŸ¥æ‰¾Unity WebGLæ¸¸æˆ
                    unity_script = container.select_one('script[src*="unity"]')
                    if unity_script:
                        logger.info(f"æ‰¾åˆ°Unity WebGLæ¸¸æˆ")
                        return 'iframe', {'iframe_url': game_url}
                    
                    # æŸ¥æ‰¾å…¶ä»–åµŒå…¥å¼æ¸¸æˆ
                    canvas = container.select_one('canvas')
                    if canvas:
                        logger.info(f"æ‰¾åˆ°Canvasæ¸¸æˆ")
                        return 'iframe', {'iframe_url': game_url}
            
            # 4. å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›Noneè¡¨ç¤ºä¸é€‚åˆæ”¶é›†
            logger.warning(f"æœªæ‰¾åˆ°å¯åµŒå…¥çš„æ¸¸æˆå†…å®¹: {game_url}")
            return None, {}
            
        except Exception as e:
            logger.error(f"åˆ¤æ–­æ¸¸æˆç±»å‹å¤±è´¥ {game_url}: {e}")
            return None, {}
    
    def _validate_iframe_url(self, iframe_url: str) -> bool:
        """éªŒè¯iframe URLæ˜¯å¦å¯ä»¥åµŒå…¥"""
        try:
            # æ£€æŸ¥URLæ ¼å¼
            parsed = urlparse(iframe_url)
            if not parsed.scheme or not parsed.netloc:
                return False
            
            # æ’é™¤ä¸é€‚åˆåµŒå…¥çš„åŸŸå
            blocked_domains = [
                'youtube.com',      # YouTubeè§†é¢‘
                'vimeo.com',        # Vimeoè§†é¢‘
                'facebook.com',     # ç¤¾äº¤åª’ä½“
                'twitter.com',      # ç¤¾äº¤åª’ä½“
                'instagram.com',    # ç¤¾äº¤åª’ä½“
                'tiktok.com',       # çŸ­è§†é¢‘
                'ads.',             # å¹¿å‘Š
                'analytics.',       # åˆ†æ
                'tracking.'         # è·Ÿè¸ª
            ]
            
            for domain in blocked_domains:
                if domain in iframe_url.lower():
                    logger.info(f"è·³è¿‡ä¸é€‚åˆåµŒå…¥çš„URL: {iframe_url}")
                    return False
            
            # å‘é€HEADè¯·æ±‚æ£€æŸ¥å¯è®¿é—®æ€§
            try:
                response = self.session.head(iframe_url, timeout=5, allow_redirects=True)
                # æ£€æŸ¥X-Frame-Optionså¤´
                frame_options = response.headers.get('X-Frame-Options', '').upper()
                if frame_options in ['DENY', 'SAMEORIGIN']:
                    logger.info(f"URLç¦æ­¢iframeåµŒå…¥: {iframe_url}")
                    return False
                
                # æ£€æŸ¥Content-Type
                content_type = response.headers.get('Content-Type', '').lower()
                if 'text/html' in content_type or 'application/' in content_type:
                    return True
                    
            except Exception as e:
                logger.warning(f"éªŒè¯iframe URLå¤±è´¥: {iframe_url}, {e}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"éªŒè¯iframe URLå¼‚å¸¸: {iframe_url}, {e}")
            return False
    
    def _is_downloadable_game(self, game_url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯å¯ä¸‹è½½çš„æ¸¸æˆæ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            parsed = urlparse(game_url)
            path = parsed.path.lower()
            
            # æ”¯æŒçš„æ¸¸æˆæ–‡ä»¶ç±»å‹
            game_extensions = ['.html', '.htm', '.swf', '.unity3d', '.wasm']
            if any(path.endswith(ext) for ext in game_extensions):
                return True
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¸¸æˆç›¸å…³è·¯å¾„
            game_paths = ['/play', '/game', '/games', 'fullscreen', 'index.html']
            if any(game_path in path for game_path in game_paths):
                # å‘é€HEADè¯·æ±‚æ£€æŸ¥æ–‡ä»¶å¤§å°å’Œç±»å‹
                try:
                    response = self.session.head(game_url, timeout=5)
                    content_length = response.headers.get('Content-Length')
                    if content_length:
                        size_mb = int(content_length) / (1024 * 1024)
                        # é™åˆ¶æ–‡ä»¶å¤§å°ï¼ˆå°äº100MBçš„æ¸¸æˆæ–‡ä»¶ï¼‰
                        if size_mb < 100:
                            return True
                except Exception:
                    pass
            
            return False
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥å¯ä¸‹è½½æ¸¸æˆå¤±è´¥: {game_url}, {e}")
            return False
    
    def _clean_title(self, title: str) -> str:
        """æ¸…ç†æ¸¸æˆæ ‡é¢˜"""
        # ç§»é™¤å¸¸è§çš„åç¼€
        suffixes = [' - Play Online', ' Game', ' Online', ' Free', ' HTML5', ' Browser']
        for suffix in suffixes:
            if title.endswith(suffix):
                title = title[:-len(suffix)]
        
        # é™åˆ¶é•¿åº¦
        if len(title) > 50:
            title = title[:47] + '...'
        
        return title.strip()
    
    def download_thumbnail(self, thumbnail_url: str, game_id: str) -> str:
        """ä¸‹è½½æ¸¸æˆç¼©ç•¥å›¾"""
        try:
            if not thumbnail_url:
                return '/games/thumbnails/default.jpg'
            
            response = self.session.get(thumbnail_url, timeout=10)
            response.raise_for_status()
            
            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            content_type = response.headers.get('content-type', '')
            if 'jpeg' in content_type or 'jpg' in content_type:
                ext = '.jpg'
            elif 'png' in content_type:
                ext = '.png'
            elif 'gif' in content_type:
                ext = '.gif'
            else:
                ext = '.jpg'
            
            filename = f"{game_id}{ext}"
            filepath = os.path.join(THUMBNAILS_DIR, filename)
            
            with open(filepath, 'wb') as f:
                f.write(response.content)
            
            logger.info(f"ä¸‹è½½ç¼©ç•¥å›¾æˆåŠŸ: {filename}")
            return f'/games/thumbnails/{filename}'
            
        except Exception as e:
            logger.error(f"ä¸‹è½½ç¼©ç•¥å›¾å¤±è´¥ {thumbnail_url}: {e}")
            return '/games/thumbnails/default.jpg'
    
    def crawl_seed_urls(self) -> List[Dict]:
        """çˆ¬å–ç§å­URL"""
        all_games = []
        
        for url in SEED_URLS:
            try:
                logger.info(f"æ­£åœ¨çˆ¬å–ç§å­URL: {url}")
                soup = self.fetch_page(url)
                if soup:
                    games = self.extract_game_info(soup, url)
                    all_games.extend(games)
                    logger.info(f"ä» {url} æå–åˆ° {len(games)} ä¸ªæ¸¸æˆ")
                
                # éšæœºå»¶è¿Ÿé¿å…è¢«å°
                time.sleep(random.uniform(2, 5))
                
            except Exception as e:
                logger.error(f"çˆ¬å–ç§å­URLå¤±è´¥ {url}: {e}")
                continue
        
        return all_games
    
    def search_games_duckduckgo(self, query: str, max_results: int = 10) -> List[str]:
        """ä½¿ç”¨DuckDuckGoæœç´¢æ¸¸æˆé¡µé¢"""
        try:
            search_url = f"https://duckduckgo.com/html/?q={quote(query)}"
            soup = self.fetch_page(search_url)
            if not soup:
                return []
            
            urls = []
            for link in soup.select('.result__a')[:max_results]:
                href = link.get('href')
                if href and href.startswith('http'):
                    urls.append(href)
            
            logger.info(f"DuckDuckGoæœç´¢ '{query}' æ‰¾åˆ° {len(urls)} ä¸ªç»“æœ")
            return urls
            
        except Exception as e:
            logger.error(f"DuckDuckGoæœç´¢å¤±è´¥ '{query}': {e}")
            return []
    
    def process_found_games(self, games: List[Dict]) -> List[Dict]:
        """å¤„ç†æ‰¾åˆ°çš„æ¸¸æˆï¼Œç”Ÿæˆæœ€ç»ˆçš„æ¸¸æˆæ•°æ®"""
        processed_games = []
        
        for i, game in enumerate(games):
            try:
                # ç”Ÿæˆæ¸¸æˆID
                game_id = str(len(self.get_existing_games()) + i + 1)
                
                # ä¸‹è½½ç¼©ç•¥å›¾
                thumbnail_path = self.download_thumbnail(game.get('thumbnail_url'), game_id)
                
                # è·å–åˆ†ç±»ID
                category_id = CATEGORY_ID_MAPPING.get(game['category'], '1')
                
                # æ„å»ºæ¸¸æˆæ•°æ®
                game_data = {
                    'id': game_id,
                    'title': game['title'],
                    'description': game['description'],
                    'category': game['category'],
                    'categoryId': category_id,
                    'thumbnail': thumbnail_path,
                    'path': f'/games/{game_id}',
                    'featured': False,
                    'type': game['type'],
                    'addedAt': datetime.now().strftime('%Y-%m-%d'),
                    'tags': self._generate_tags(game)
                }
                
                # æ·»åŠ ç±»å‹ç‰¹å®šçš„æ•°æ®
                if game['type'] == 'iframe':
                    # ç¡®ä¿iframe URLå¯ä»¥åµŒå…¥
                    iframe_url = game['game_data']['iframe_url']
                    if self._validate_iframe_url(iframe_url):
                        game_data['iframeUrl'] = iframe_url
                        logger.info(f"âœ… æ·»åŠ iframeæ¸¸æˆ: {game_data['title']} -> {iframe_url}")
                    else:
                        logger.warning(f"âŒ è·³è¿‡æ— æ³•åµŒå…¥çš„iframeæ¸¸æˆ: {game_data['title']}")
                        continue
                else:
                    # staticç±»å‹æ¸¸æˆ
                    static_url = game['game_data'].get('static_url')
                    if static_url and self._is_downloadable_game(static_url):
                        game_data['staticPath'] = static_url
                        logger.info(f"âœ… æ·»åŠ é™æ€æ¸¸æˆ: {game_data['title']} -> {static_url}")
                    else:
                        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„é™æ€URLï¼Œè®¾ç½®ä¸ºæœ¬åœ°è·¯å¾„
                        game_data['staticPath'] = f'/games/{game_id}/index.html'
                        logger.info(f"ğŸ“ è®¾ç½®æœ¬åœ°è·¯å¾„: {game_data['title']} -> {game_data['staticPath']}")
                
                processed_games.append(game_data)
                
            except Exception as e:
                logger.error(f"å¤„ç†æ¸¸æˆå¤±è´¥: {e}")
                continue
        
        logger.info(f"ğŸ® æˆåŠŸå¤„ç† {len(processed_games)} ä¸ªå¯åµŒå…¥æ¸¸æˆ")
        return processed_games
    
    def _generate_tags(self, game: Dict) -> List[str]:
        """ä¸ºæ¸¸æˆç”Ÿæˆæ ‡ç­¾"""
        tags = [game['category']]
        
        title_lower = game['title'].lower()
        desc_lower = (game.get('description') or '').lower()
        
        # æ ¹æ®æ ‡é¢˜å’Œæè¿°æ·»åŠ æ ‡ç­¾
        tag_keywords = {
            'å¤šäºº': ['multiplayer', 'multi', 'å¤šäºº', 'è”æœº'],
            'å•äºº': ['single', 'solo', 'å•äºº'],
            '3D': ['3d', 'ä¸‰ç»´'],
            '2D': ['2d', 'äºŒç»´', 'pixel'],
            'å¤å¤': ['retro', 'classic', 'ç»å…¸', 'æ€€æ—§'],
            'å¯çˆ±': ['cute', 'kawaii', 'å¯çˆ±', 'èŒ'],
            'å›°éš¾': ['hard', 'difficult', 'å›°éš¾', 'æŒ‘æˆ˜'],
            'ç®€å•': ['easy', 'simple', 'ç®€å•', 'è½»æ¾']
        }
        
        for tag, keywords in tag_keywords.items():
            if any(keyword in title_lower or keyword in desc_lower for keyword in keywords):
                tags.append(tag)
        
        return tags[:5]  # é™åˆ¶æ ‡ç­¾æ•°é‡
    
    def get_existing_games(self) -> List[Dict]:
        """è·å–ç°æœ‰çš„æ¸¸æˆæ•°æ®"""
        try:
            if not os.path.exists(GAMES_DATA_FILE):
                return []
            
            with open(GAMES_DATA_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç®€å•è§£æç°æœ‰æ¸¸æˆæ•°æ®ï¼ˆè¿™é‡Œå¯ä»¥æ”¹è¿›ä¸ºæ›´ç²¾ç¡®çš„è§£æï¼‰
            import re
            games_match = re.search(r'export const games: Game\[\] = (\[.*?\]);', content, re.DOTALL)
            if games_match:
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æ
                return []  # è¿”å›ç©ºåˆ—è¡¨ï¼Œè®©æ–°æ¸¸æˆä»ç°æœ‰IDç»§ç»­
            
            return []
            
        except Exception as e:
            logger.error(f"è¯»å–ç°æœ‰æ¸¸æˆæ•°æ®å¤±è´¥: {e}")
            return []
    
    def save_games_to_file(self, new_games: List[Dict]):
        """å°†æ–°æ¸¸æˆä¿å­˜åˆ°games.tsæ–‡ä»¶å’ŒJSONæ–‡ä»¶"""
        try:
            # 1. ä¿å­˜ä¸ºJSONæ–‡ä»¶ï¼Œæ–¹ä¾¿æŸ¥çœ‹å’Œè°ƒè¯•
            json_file = os.path.join(PROJECT_ROOT, 'scripts', 'crawled_games.json')
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(new_games, f, ensure_ascii=False, indent=2)
            logger.info(f"æˆåŠŸä¿å­˜ {len(new_games)} ä¸ªæ–°æ¸¸æˆåˆ°JSONæ–‡ä»¶: {json_file}")
            
            # 2. è¯»å–ç°æœ‰çš„games.tsæ–‡ä»¶
            if os.path.exists(GAMES_DATA_FILE):
                with open(GAMES_DATA_FILE, 'r', encoding='utf-8') as f:
                    content = f.read()
            else:
                content = ""
            
            # ç”Ÿæˆæ–°æ¸¸æˆçš„TypeScriptä»£ç 
            new_games_code = ""
            for game in new_games:
                # é¢„å¤„ç†å­—ç¬¦ä¸²ï¼Œé¿å…åœ¨f-stringä¸­ä½¿ç”¨åæ–œæ 
                title_escaped = game['title'].replace("'", "\\'")
                desc_escaped = game['description'].replace("'", "\\'")
                
                new_games_code += f"""  {{
    id: '{game['id']}',
    title: '{title_escaped}',
    description: '{desc_escaped}',
    category: '{game['category']}',
    categoryId: '{game['categoryId']}',
    thumbnail: '{game['thumbnail']}',
    path: '{game['path']}',
    featured: {str(game['featured']).lower()},
    type: '{game['type']}',"""
                
                if game['type'] == 'iframe':
                    new_games_code += f"\n    iframeUrl: '{game['iframeUrl']}',"
                else:
                    new_games_code += f"\n    staticPath: '{game['staticPath']}',"
                
                new_games_code += f"""
    addedAt: '{game['addedAt']}',
    tags: {json.dumps(game['tags'], ensure_ascii=False)}
  }},
"""
            
            # å¦‚æœæ–‡ä»¶å­˜åœ¨ä¸”åŒ…å«æ¸¸æˆæ•°ç»„ï¼Œè¿½åŠ æ–°æ¸¸æˆ
            if content and 'export const games: Game[] = [' in content:
                # æ‰¾åˆ°æ¸¸æˆæ•°ç»„ç»“æŸçš„ä½ç½®
                array_end_pos = content.find('];', content.find('export const games: Game[] = ['))
                if array_end_pos != -1:
                    # åœ¨æ•°ç»„ç»“æŸå‰æ’å…¥æ–°æ¸¸æˆ
                    new_content = content[:array_end_pos] + new_games_code + content[array_end_pos:]
                else:
                    logger.error("æ— æ³•æ‰¾åˆ°æ¸¸æˆæ•°ç»„ç»“æŸä½ç½®")
                    new_content = content
            else:
                # åˆ›å»ºæ–°æ–‡ä»¶
                new_content = f"""import {{ Game, Category }} from '../types';

export const categories: Category[] = [
  {{ id: '1', name: 'ä¼‘é—²', description: 'ç®€å•æœ‰è¶£çš„ä¼‘é—²æ¸¸æˆï¼Œé€‚åˆæ‰€æœ‰å¹´é¾„æ®µç©å®¶', count: 125, slug: 'casual' }},
  {{ id: '2', name: 'ç›Šæ™º', description: 'é”»ç‚¼å¤§è„‘çš„ç›Šæ™ºæ¸¸æˆï¼Œæå‡æ€ç»´èƒ½åŠ›', count: 98, slug: 'puzzle' }},
  {{ id: '3', name: 'åŠ¨ä½œ', description: 'åˆºæ¿€çš„åŠ¨ä½œæ¸¸æˆï¼Œè€ƒéªŒä½ çš„ååº”é€Ÿåº¦', count: 84, slug: 'action' }},
  {{ id: '4', name: 'å¡ç‰Œ', description: 'å¡ç‰Œå’Œæ£‹ç‰Œç±»æ¸¸æˆï¼Œç­–ç•¥ä¸è¿æ°”çš„ç»“åˆ', count: 52, slug: 'card' }},
  {{ id: '5', name: 'ä½“è‚²', description: 'å„ç±»ä½“è‚²æ¨¡æ‹Ÿæ¸¸æˆï¼Œæ„Ÿå—ä½“è‚²ç«æŠ€çš„ä¹è¶£', count: 43, slug: 'sports' }},
  {{ id: '6', name: 'æ£‹ç›˜', description: 'ç»å…¸çš„æ£‹ç›˜æ¸¸æˆï¼Œè€ƒéªŒæˆ˜ç•¥æ€ç»´', count: 38, slug: 'board' }},
];

export const games: Game[] = [
{new_games_code}];

// è¾…åŠ©å‡½æ•°
export const getFeaturedGames = (): Game[] => {{
  return games.filter(game => game.featured);
}};

export const getRecentGames = (limit: number = 8): Game[] => {{
  return [...games]
    .sort((a, b) => new Date(b.addedAt).getTime() - new Date(a.addedAt).getTime())
    .slice(0, limit);
}};

export const getGamesByCategory = (categoryId: string): Game[] => {{
  return games.filter(game => game.categoryId === categoryId);
}};

export const getGameById = (id: string): Game | undefined => {{
  return games.find(game => game.id === id);
}};

export const getCategoryById = (id: string): Category | undefined => {{
  return categories.find(category => category.id === id);
}};
"""
            
            # ä¿å­˜æ–‡ä»¶
            with open(GAMES_DATA_FILE, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            logger.info(f"æˆåŠŸè¿½åŠ  {len(new_games)} ä¸ªæ–°æ¸¸æˆåˆ° {GAMES_DATA_FILE}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ¸¸æˆæ•°æ®å¤±è´¥: {e}")
    
    def run(self, max_games: int = 50):
        """è¿è¡Œçˆ¬è™«"""
        logger.info("å¼€å§‹è¿è¡Œæ¸¸æˆçˆ¬è™«...")
        
        # 1. çˆ¬å–ç§å­URL
        logger.info("æ­¥éª¤1: çˆ¬å–ç§å­URL...")
        seed_games = self.crawl_seed_urls()
        
        # 2. æœç´¢å¼•æ“æœç´¢
        logger.info("æ­¥éª¤2: ä½¿ç”¨æœç´¢å¼•æ“æœç´¢...")
        search_games = []
        for query in SEARCH_QUERIES[:5]:  # é™åˆ¶æœç´¢æŸ¥è¯¢æ•°é‡
            try:
                urls = self.search_games_duckduckgo(query, 5)
                for url in urls:
                    soup = self.fetch_page(url)
                    if soup:
                        games = self.extract_game_info(soup, url)
                        search_games.extend(games)
                time.sleep(random.uniform(3, 6))
            except Exception as e:
                logger.error(f"æœç´¢æŸ¥è¯¢å¤±è´¥ '{query}': {e}")
                continue
        
        # 3. åˆå¹¶å’Œå»é‡
        all_games = seed_games + search_games
        unique_games = []
        seen_titles = set()
        
        for game in all_games:
            title_key = game['title'].lower().strip()
            if title_key not in seen_titles:
                seen_titles.add(title_key)
                unique_games.append(game)
        
        logger.info(f"å»é‡åå…±æ‰¾åˆ° {len(unique_games)} ä¸ªæ¸¸æˆ")
        
        # 4. é™åˆ¶æ•°é‡å¹¶å¤„ç†
        if len(unique_games) > max_games:
            unique_games = unique_games[:max_games]
        
        logger.info("æ­¥éª¤3: å¤„ç†æ¸¸æˆæ•°æ®...")
        processed_games = self.process_found_games(unique_games)
        
        # 5. ä¿å­˜åˆ°æ–‡ä»¶
        if processed_games:
            logger.info("æ­¥éª¤4: ä¿å­˜æ¸¸æˆæ•°æ®...")
            self.save_games_to_file(processed_games)
            logger.info(f"çˆ¬è™«è¿è¡Œå®Œæˆï¼æˆåŠŸæ·»åŠ  {len(processed_games)} ä¸ªæ¸¸æˆ")
        else:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¸¸æˆæ•°æ®")

    def validate_game_data(self, game_info: Dict) -> bool:
        """éªŒè¯æ¸¸æˆæ•°æ®æ˜¯å¦æœ‰æ•ˆ"""
        try:
            title = game_info.get('title', '').strip()
            description = game_info.get('description', '').strip()
            game_url = game_info.get('game_url', '')
            
            # 1. æ£€æŸ¥æ ‡é¢˜æœ‰æ•ˆæ€§
            invalid_titles = [
                'unleash the gamer',
                'play games',
                'free games',
                'online games',
                'game portal',
                'gaming platform',
                'entertainment',
                'company',
                'developer',
                'publisher',
                'studio',
                'browse games',
                'all games'
            ]
            
            title_lower = title.lower()
            if any(invalid in title_lower for invalid in invalid_titles):
                logger.info(f"âŒ è·³è¿‡æ— æ•ˆæ ‡é¢˜: {title}")
                return False
            
            # 2. æ£€æŸ¥æ ‡é¢˜é•¿åº¦å’Œæ ¼å¼
            if len(title) < 3 or len(title) > 100:
                logger.info(f"âŒ æ ‡é¢˜é•¿åº¦ä¸åˆé€‚: {title}")
                return False
            
            # 3. æ£€æŸ¥æ˜¯å¦æ˜¯å…¬å¸/ç½‘ç«™ä»‹ç»
            company_keywords = [
                'we develop',
                'we publish',
                'we reach',
                'million players',
                'international',
                'company',
                'entertainment company',
                'game developer',
                'our audience',
                'multiplayer mobile games',
                'digital games and entertainment'
            ]
            
            desc_lower = description.lower()
            if any(keyword in desc_lower for keyword in company_keywords):
                logger.info(f"âŒ è·³è¿‡å…¬å¸ä»‹ç»: {title}")
                return False
            
            # 4. æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç«™é¦–é¡µæˆ–åˆ†ç±»é¡µ
            invalid_url_patterns = [
                '/games$',
                '/games/$',
                'miniclip.com/games$',
                'itch.io/games$',
                'gamejolt.com/games$',
                'newgrounds.com/games$',
                '/browse$',
                '/category$',
                '/tag/$'
            ]
            
            for pattern in invalid_url_patterns:
                if re.search(pattern, game_url, re.IGNORECASE):
                    logger.info(f"âŒ è·³è¿‡ç½‘ç«™é¦–é¡µ/åˆ†ç±»é¡µ: {game_url}")
                    return False
            
            logger.info(f"âœ… æ¸¸æˆæ•°æ®éªŒè¯é€šè¿‡: {title}")
            return True
            
        except Exception as e:
            logger.error(f"éªŒè¯æ¸¸æˆæ•°æ®å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    crawler = GameCrawler()
    crawler.run(max_games=30)  # é™åˆ¶æœ€å¤šçˆ¬å–30ä¸ªæ¸¸æˆ

if __name__ == '__main__':
    main() 